{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPvo6Mxw6a/F7FiQ734GqEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raspberry765/deep-metric-learning/blob/main/outlier_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-metric-learning\n",
        "!pip install faiss-gpu\n",
        "!pip install torchsummary\n",
        "!pip install plotly==5.14.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of8MhpFznyab",
        "outputId": "261e18eb-6b51-4885-c2aa-acd804df2357"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-metric-learning in /usr/local/lib/python3.9/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pytorch-metric-learning) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from pytorch-metric-learning) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-metric-learning) (2.0.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from pytorch-metric-learning) (1.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (16.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->pytorch-metric-learning) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.9/dist-packages (1.7.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.9/dist-packages (1.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: plotly==5.14.1 in /usr/local/lib/python3.9/dist-packages (5.14.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly==5.14.1) (8.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly==5.14.1) (23.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "from pytorch_metric_learning import losses, testers\n",
        "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
        "from torchsummary import summary\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from torch.utils.data.dataset import Subset\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "import random\n",
        "random.seed(314) # 乱数シードを314に設定"
      ],
      "metadata": {
        "id": "vp3LVLtBnzmx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "img_mean, img_std = (0.1307,), (0.3081,) #MNISTの平均と標準偏差  https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457 \n",
        "\n",
        "\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-m / s for m, s in zip(img_mean, img_std)], std=[1 / s for s in img_std]\n",
        ")\n",
        "\n",
        "\n",
        "def imshow(img, figsize=(8, 4)):\n",
        "    img = inv_normalize(img)\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def imshow_many(dataset, outliers, n=32):\n",
        "    imgs = [\n",
        "        dataset[outliers[i]][0]\n",
        "        for i in np.random.choice(\n",
        "            len(outliers), size=min(n, len(outliers)), replace=False\n",
        "        )\n",
        "    ]\n",
        "    imshow(torchvision.utils.make_grid(imgs))"
      ],
      "metadata": {
        "id": "U4Fd-OmXnzve"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize(img_mean, img_std)]\n",
        ") #MNISTの平均と標準偏差を画像に対して前処理を行うためのパラメーター\n",
        "\n",
        "\n",
        "\n",
        "dataset1 = datasets.MNIST(\"./sample_data/\", train=True, download=True, transform=transform) #トランスフォームを適用して、ダウンロード\n",
        "dataset2 = datasets.MNIST(\"./sample_data/\", train=False, transform=transform) #トランスフォームを適用して、ダウンロード\n",
        "\n"
      ],
      "metadata": {
        "id": "qDVxSgVqn_Sp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f908VbGnxdp",
        "outputId": "ff488e1d-1fc8-4523-8c46-e85f7e3af1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        ##torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1)\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1) #MNISTのデータはグレースケールだから、channel数は1である\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.25)\n",
        "        self.dropout3 = nn.Dropout2d(0.5)\n",
        "        self.fc1 = nn.Linear(15488, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        ##torch.nn.functional.max_pool2d(input, kernel_size, stride=kernel_size)\n",
        "        #max_pool2dのstrideのデフォルトはkernel_size\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "def train(model, loss_func, device, train_loader, optimizer, loss_optimizer, epoch):\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss_optimizer.zero_grad()\n",
        "        embeddings = model(data)\n",
        "        #loss_func = losses.SubCenterArcFaceLoss(num_classes=10, embedding_size=256).to(device) #0~9の数字を分類するため　10classに分類する、embedding_sizeは最終出力のunits数\n",
        "        loss = loss_func(embeddings, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(\"Epoch {} Iteration {}: Loss = {}\".format(epoch, batch_idx, loss))\n",
        "            numpy_loss = loss.cpu().detach().numpy()\n",
        "            loss_list.append(numpy_loss)\n",
        "            torch.save(model, \"model_dml\"+ str(epoch)+ \"_\" + str(batch_idx)  + \".pth\")\n",
        "            #print(numpy_loss)            \n",
        "    return loss_list\n",
        "\n",
        "\n",
        "### convenient function from pytorch-metric-learning ###\n",
        "def get_all_embeddings(dataset, model,eval):\n",
        "    tester = testers.BaseTester()\n",
        "    return tester.get_all_embeddings(dataset, model)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9Eg5xzZKod4b"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import __main__\n",
        "setattr(__main__, \"Net\", Net)\n",
        "model = Net().to(device)\n",
        "model.eval()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)#defalut lr=0.01 #ハイパーパラメーター\n",
        "loss_func = losses.SubCenterArcFaceLoss(num_classes=10, embedding_size=256).to(device) #0~9の数字を分類するため　10classに分類する、embedding_sizeは最終出力のunits数\n",
        "loss_optimizer = torch.optim.Adam(loss_func.parameters(), lr=1e-4)#ハイパーパラメーター\n",
        "\n",
        "#model = model.to(device)\n",
        "\n",
        "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "#model.eval()\n",
        "model = model.load_state_dict(torch.load(\"/content/drive/MyDrive/deep_metric_learning/model_dml.pth\"))\n",
        "#model.eval()#←Error\n",
        "optimizer.load_state_dict(torch.load(\"/content/drive/MyDrive/deep_metric_learning/optim_dml.pth\"))\n",
        "loss_func.load_state_dict(torch.load(\"/content/drive/MyDrive/deep_metric_learning/loss_func_dml.pth\"))\n",
        "loss_optimizer.load_state_dict(torch.load(\"/content/drive/MyDrive/deep_metric_learning/loss_optim_dml.pth\"))\n",
        "#model.eval()#←Error\n",
        "\n"
      ],
      "metadata": {
        "id": "Qd6N5KHMHWqK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings, train_labels = get_all_embeddings(dataset1, model)\n",
        "\n",
        "outliers, _ = loss_func.get_outliers(train_embeddings, train_labels.squeeze(1)) #train modelを異常検知している #lr=0.01 outlier=98\n",
        "print(f\"There are {len(outliers)} outliers\")\n",
        "imshow_many(dataset1, outliers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "Ub7idoVnp08p",
        "outputId": "d6dd4601-7265-4803-abaf-a001047f4a32"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f9e220cbbf15>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutliers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#train modelを異常検知している #lr=0.01 outlier=98\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There are {len(outliers)} outliers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimshow_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutliers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: get_all_embeddings() missing 1 required positional argument: 'eval'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cYxDfA5HVb4U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}